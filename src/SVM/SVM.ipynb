{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17ab212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to Project Root.\n",
      "Current Working Directory: d:\\college\\Senior Year\\Machine Learning\\Material-Stream-Identification-System\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if we are in the nested 'SVM' folder\n",
    "if os.getcwd().endswith('SVM'):\n",
    "    os.chdir('../..')  # Go up two levels to the project root\n",
    "    print(\"Directory changed to Project Root.\")\n",
    "\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23ff2f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: ['cardboard', 'glass', 'metal', 'paper']\n",
      "Processing class 'cardboard' with 1540 images...\n",
      "Processing class 'glass' with 1540 images...\n",
      "Processing class 'metal' with 1540 images...\n",
      "Processing class 'paper' with 1540 images...\n",
      "Feature extraction done!\n",
      "X shape: (6160, 8158)\n",
      "y shape: (6160,)\n",
      "y_encoded shape: (6160,)\n",
      "Class mapping: {np.str_('cardboard'): np.int64(0), np.str_('glass'): np.int64(1), np.str_('metal'): np.int64(2), np.str_('paper'): np.int64(3)}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "augmentedDir = \"data\\\\augmented\"  \n",
    "classes = [d for d in os.listdir(augmentedDir) if os.path.isdir(os.path.join(augmentedDir,d))]\n",
    "print(\"Classes found:\", classes)\n",
    "\n",
    "IMG_SIZE = (128, 128)\n",
    "LBP_RADIUS = 1\n",
    "LBP_N_POINTS = 8 * LBP_RADIUS\n",
    "LBP_METHOD = 'uniform'\n",
    "HOG_PIXELS_PER_CELL = (8, 8)\n",
    "HOG_CELLS_PER_BLOCK = (2, 2)\n",
    "HOG_ORIENTATIONS = 9\n",
    "COLOR_BINS = 16  \n",
    "\n",
    "#  Feature Extraction\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "for cls in classes:\n",
    "    folder = os.path.join(augmentedDir, cls)\n",
    "    files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "    print(f\"Processing class '{cls}' with {len(files)} images...\")\n",
    "    \n",
    "    for file in files:\n",
    "        img_path = os.path.join(folder, file)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        # Resize\n",
    "        img = cv2.resize(img, IMG_SIZE)\n",
    "        \n",
    "        # Convert to grayscale for HOG and LBP\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # HOG feature\n",
    "        hog_feat = hog(\n",
    "            gray,\n",
    "            orientations=HOG_ORIENTATIONS,\n",
    "            pixels_per_cell=HOG_PIXELS_PER_CELL,\n",
    "            cells_per_block=HOG_CELLS_PER_BLOCK,\n",
    "            block_norm='L2-Hys',\n",
    "            transform_sqrt=True,\n",
    "            feature_vector=True\n",
    "        )\n",
    "        \n",
    "        # LBP feature\n",
    "        lbp = local_binary_pattern(gray, LBP_N_POINTS, LBP_RADIUS, LBP_METHOD)\n",
    "        (lbp_hist, _) = np.histogram(lbp.ravel(),\n",
    "                                     bins=np.arange(0, LBP_N_POINTS + 3),\n",
    "                                     range=(0, LBP_N_POINTS + 2))\n",
    "        lbp_hist = lbp_hist.astype(\"float\")\n",
    "        lbp_hist /= (lbp_hist.sum() + 1e-6)\n",
    "        \n",
    "        # Color histogram (HSV)\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h_hist = cv2.calcHist([hsv], [0], None, [COLOR_BINS], [0, 180])\n",
    "        s_hist = cv2.calcHist([hsv], [1], None, [COLOR_BINS], [0, 256])\n",
    "        v_hist = cv2.calcHist([hsv], [2], None, [COLOR_BINS], [0, 256])\n",
    "        color_hist = np.concatenate([h_hist, s_hist, v_hist]).ravel()\n",
    "        color_hist = color_hist / (color_hist.sum() + 1e-6)\n",
    "\n",
    "        # merge all features\n",
    "        feature_vector = np.concatenate([hog_feat, lbp_hist, color_hist])\n",
    "        \n",
    "        X.append(feature_vector)\n",
    "        y.append(cls)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(\"Feature extraction done!\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"y_encoded shape:\", y_encoded.shape)\n",
    "print(\"Class mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb593002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (6160, 8158)\n",
      "Original y shape: (6160,)\n",
      "Class mapping: {np.str_('cardboard'): np.int64(0), np.str_('glass'): np.int64(1), np.str_('metal'): np.int64(2), np.str_('paper'): np.int64(3)}\n",
      "y_encoded shape: (6160,)\n",
      "Before scaling:\n",
      "X_train shape: (4928, 8158)\n",
      "X_test shape: (1232, 8158)\n",
      "After scaling:\n",
      "X_train shape: (4928, 8158)\n",
      "X_test shape: (1232, 8158)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print(\"Original X shape:\", X.shape)\n",
    "print(\"Original y shape:\", y.shape)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "class_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Class mapping:\", class_mapping)\n",
    "print(\"y_encoded shape:\", y_encoded.shape)\n",
    "\n",
    "# split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(\"Before scaling:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "\n",
    "# Standardization (Mean=0, Std=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"After scaling:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6417abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling done in previous step start training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2792c52",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[2. 1. 2. ... 3. 3. 1.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     12\u001b[0m max_val_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred_prob)\n\u001b[0;32m     16\u001b[0m y_pred_classes \u001b[38;5;241m=\u001b[39m [ np\u001b[38;5;241m.\u001b[39margmax(prob_list) \u001b[38;5;28;01mif\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mmax(prob_list)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Confidence_Threshold) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m6\u001b[39m  \u001b[38;5;28;01mfor\u001b[39;00m prob_list \u001b[38;5;129;01min\u001b[39;00m y_pred_prob ]\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mscore(y_test,y_pred_classes))\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:572\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    549\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 572\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X), sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\sklearn\\svm\\_base.py:822\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    820\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 822\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\sklearn\\svm\\_base.py:436\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \n\u001b[0;32m    423\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 436\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_for_predict(X)\n\u001b[0;32m    437\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\sklearn\\svm\\_base.py:614\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    611\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[1;32m--> 614\u001b[0m     X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m    615\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    616\u001b[0m         X,\n\u001b[0;32m    617\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    618\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m    619\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    620\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    621\u001b[0m         reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    622\u001b[0m     )\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m    625\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:1093\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1087\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1088\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1089\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1090\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1091\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1092\u001b[0m             )\n\u001b[1;32m-> 1093\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1098\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1099\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[2. 1. 2. ... 3. 3. 1.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model = SVC( probability= True)\n",
    "\n",
    "model.fit (X_train, y_train)\n",
    "\n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "\n",
    "Confidence_Threshold = 0.7\n",
    "max_val = np.max(y_pred_prob)\n",
    "max_val_idx = np.argmax(y_pred_prob)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_classes = [ np.argmax(prob_list) if (np.max(prob_list)>= Confidence_Threshold) else 6  for prob_list in y_pred_prob ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2586e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8717532467532467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(model.score(X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
